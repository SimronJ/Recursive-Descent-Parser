{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "***Student Name:*** Simranjeet Singh\n",
    "    \n",
    "    \n",
    "## Submission\n",
    "\n",
    "After answering all the questions, save your work in **Notebook** format file. Do not submit PDF files.\n",
    "    \n",
    "- Double-click on this cell\n",
    "- Enter your name in the above placeholder, and evaluate this cell to reneder it correctly\n",
    "- Save your work by pressing <span class=\"fa-save fa\"/> button in the toolbar\n",
    "- Go to menu \"File\" -> \"Download as\"\n",
    "- Select \"Notebook (.ipynb)\"\n",
    "- Use downloaded file for Balckboard submission \n",
    "\n",
    "For more information, see https://www.codecademy.com/articles/how-to-use-jupyter-notebooks\n",
    "\n",
    "### Coding Style\n",
    "\n",
    "- Use functional F# style for writing your programs.\n",
    "- Make sure that you do not use mutable variables & loops.\n",
    "- Any imperative style programming is prohibited unless specified in the problem description.\n",
    "\n",
    "For additional information of F# coding style see [F# Style Guide](https://docs.microsoft.com/en-us/dotnet/fsharp/style-guide/).\n",
    "\n",
    "### Before You Submit\n",
    "\n",
    "You are required to test that your submission works properly before submission. Make sure that your program compiles without errors. Once you have verified that the submission is correct, you can submit your work.\n",
    "\n",
    "### Your Submission\n",
    "\n",
    "Program submissions should be done through the Blackboard.\n",
    "\n",
    "### F# Interactive Console\n",
    "\n",
    "You can run your code in F# Interactive console inside Jupyter. The interactive console provides more relevant compilation information which might not be available in the notebooks cells.\n",
    "\n",
    "For accessing F# Interactive console\n",
    "- Open a new terminal window, see https://youtu.be/IMdfXGHzz5g?t=840\n",
    "- Type command `dotnet fsi`\n",
    "- Copy your code into the console for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Problem\n",
    "\n",
    "In this project you write a recursive descent parser for a specific grammar.\n",
    "\n",
    "1. Find your grammar definition in [grammars.md](grammars.md) file which corresponds to your ID.\n",
    "2. Make appropriate changes to your grammar to convert it to the LL form if necessary\n",
    "   - No left recursion\n",
    "   - Pairwise disjoint productions\n",
    "4. Write a recursive descent parser for your grammar. Your parser should output for every test sentence:\n",
    "   - A test sentence itself\n",
    "   - A list the grammar rules required to parse a correct sentence.\n",
    "   - See a parsing example in [rd-parser.ipynb](https://github.com/wildart/parsers/blob/master/rd-parser.ipynb) script.\n",
    "5. Use provided sentences from [grammars.md](grammars.md) file to test correctness of your parser.\n",
    "\n",
    "You recursive-descent parser must output list of grammar rules required to parse a valid sentence of produced by your grammar.\n",
    "Several sentences are provided to you. If case of the error in parser input, i.e. invalid sentence, your parser need to output error and terminate execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your **LL grammar** in the following cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S -> eaf | eUT\n",
    "T -> e\n",
    "U -> aeV\n",
    "V -> cSV | ε"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your **recursive descent parser** in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-205.Microsoft.DotNet.Interactive.Http.HttpPort' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://10.0.1.101:1024/\", \"http://127.0.0.1:1024/\"])\r\n",
       "        .then((root) => {\r\n",
       "        // use probing to find host url and api resources\r\n",
       "        // load interactive helpers and language services\r\n",
       "        let dotnetInteractiveRequire = require.config({\r\n",
       "        context: '205.Microsoft.DotNet.Interactive.Http.HttpPort',\r\n",
       "                paths:\r\n",
       "            {\r\n",
       "                'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "        }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "\r\n",
       "            window.configureRequireFromExtension = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S → eaf | eUT \n",
      "T → e \n",
      "U → aeV \n",
      "V → cSV | ε \n",
      "[|(S, [Terminal E; Terminal A; Terminal F]);\n",
      "  (S, [Terminal E; NonTerminal U; NonTerminal T]); (T, [Terminal E]);\n",
      "  (U, [Terminal A; Terminal E; NonTerminal V]);\n",
      "  (V, [Terminal C; NonTerminal S; NonTerminal V]); (V, [Terminal EPS])|]\n",
      "Grammar:\n",
      "1: S → eaf\n",
      "2: S → eUT\n",
      "3: T → e\n",
      "4: U → aeV\n",
      "5: V → cSV\n",
      "6: V → ε\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Load some auxiliary tools\n",
    "#load \"grammartools.fsx\"\n",
    "open CSCI374.GrammarTools\n",
    "open CSCI374.ParserTypes\n",
    "\n",
    "type Tokenizer(grammar: PRODUCTION [], verbose: bool) =\n",
    "    let mutable inputState = []\n",
    "    let mutable curentToken = INVALID\n",
    "\n",
    "    // Access to the\n",
    "    member this.CurrentToken = curentToken    \n",
    "    member this.NextToken() =\n",
    "        let tkn, input = CSCI374.Lexer.token inputState\n",
    "        inputState <- input\n",
    "        curentToken <- tkn\n",
    "        this\n",
    "    \n",
    "    member this.InputState\n",
    "        with set(str) = inputState <- Seq.toList str\n",
    "    member this.IsVerbose = verbose\n",
    "    member this.PrintRule ruleIdx =\n",
    "        printGrammarRule false grammar ruleIdx // print rule\n",
    "    new(grammar) = Tokenizer(grammar, false)\n",
    "\n",
    "/// This infix operator function provides verbose output while calling\n",
    "/// a particular production rule\n",
    "let (==>) (cnxt:Tokenizer) (prod:Tokenizer->Tokenizer) =\n",
    "    if cnxt.IsVerbose then\n",
    "        printfn \"Enter <%A> with token `%A`\" prod cnxt.CurrentToken\n",
    "    let nextcnxt = prod cnxt\n",
    "    if cnxt.IsVerbose then\n",
    "        printfn \"Exit <%A> with token `%A`\" prod cnxt.CurrentToken\n",
    "    nextcnxt\n",
    "    \n",
    "/// This infix operator function will allow to print a production rule\n",
    "/// call `cnxt @ 2` will print second grammar rule\n",
    "let (@) (cnxt:Tokenizer) ruleIdx =\n",
    "    cnxt.PrintRule ruleIdx\n",
    "    cnxt\n",
    "\n",
    "let grammar = parseGrammarString \"\"\"\n",
    "S -> eaf | eUT\n",
    "T -> e\n",
    "U -> aeV\n",
    "V -> cSV | ε\n",
    "\"\"\"\n",
    "printfn \"%A\" grammar\n",
    "\n",
    "// Show grammar rules\n",
    "printGrammar grammar\n",
    "\n",
    "let rec ProdS (cnxt:Tokenizer) =\n",
    "    // check the current token is `E` then move to next token because S -> eaf | eUT\n",
    "    if cnxt.CurrentToken = E then\n",
    "        cnxt.NextToken() |> ignore\n",
    "        if cnxt.CurrentToken = A then\n",
    "        // 1: S → eaf\n",
    "         cnxt @(1)==> Match A ==> Match F \n",
    "        else\n",
    "            // 2: S → eUT\n",
    "          cnxt @(2)==> Match E ==> ProdU ==> ProdT\n",
    "    else\n",
    "        cnxt\n",
    "/// The function for production T → e is straight forward: match nonterminal `e`\n",
    "and ProdT (cnxt:Tokenizer) =\n",
    "    // 3: T -> e\n",
    "    cnxt @(3)==> Match E\n",
    "\n",
    "and ProdU (cnxt:Tokenizer) =\n",
    "    // 4: U → aeV\n",
    "    cnxt @(4)==> Match A ==> Match E ==> ProdV\n",
    "\n",
    "and ProdV (cnxt:Tokenizer) =\n",
    "    if cnxt.CurrentToken = C then\n",
    "        //5: V → cSV\n",
    "        cnxt.NextToken() @(5) ==> ProdS ==> ProdV\n",
    "    else\n",
    "        //6: V → ε\n",
    "        cnxt @(6) ==> Match EPS \n",
    "\n",
    "/// For each terminal symbol compare it with a current token\n",
    "/// and if they match, continue with the next token, else there is an error\n",
    "and Match term cnxt =\n",
    "    if cnxt.IsVerbose then printfn \"Match %A with %A\" term cnxt.CurrentToken\n",
    "    //printf \"The Term `%A` and the current Token `%A`\" term cnxt.CurrentToken\n",
    "    // if we matched the current token with a terminal symbol\n",
    "    if term = cnxt.CurrentToken then\n",
    "        cnxt.NextToken() // read next token\n",
    "    else\n",
    "        failwith (sprintf \"Cannot match symbol `%A` with `%A`\" term cnxt.CurrentToken)\n",
    "    \n",
    "/// Start parsing by calling starting symbol function\n",
    "let parser (cnxt:Tokenizer) :Tokenizer =    \n",
    "    // Read token and pass it to the function for S rule\n",
    "    cnxt.NextToken() ==> ProdS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your recursive recursive descent **parser tests** in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter <<fun:it@1>> with token `E`\n",
      "1: S → eaf\n",
      "Enter <<fun:ProdS@58>> with token `A`\n",
      "Match A with A\n",
      "Exit <<fun:ProdS@58>> with token `E`\n",
      "Enter <<fun:ProdS@58-1>> with token `E`\n",
      "Match F with E\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0006.it@1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0006>.$FSI_0006.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0006.it@1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0006>.$FSI_0006.main@()",
      "   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)",
      "   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at FSI_0005.ProdS(Tokenizer cnxt)",
      "   at FSI_0006.it@1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at <StartupCode$FSI_0006>.$FSI_0006.main@()"
     ]
    }
   ],
   "source": [
    "Tokenizer(grammar, true, InputState=\"eaeceafceaeceafee\") |> parser |> ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter <<fun:it@1-1>> with token `E`\n",
      "1: S → eaf\n",
      "Enter <<fun:ProdS@58>> with token `A`\n",
      "Match A with A\n",
      "Exit <<fun:ProdS@58>> with token `E`\n",
      "Enter <<fun:ProdS@58-1>> with token `E`\n",
      "Match F with E\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0007.it@1-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0007>.$FSI_0007.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0007.it@1-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0007>.$FSI_0007.main@()",
      "   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)",
      "   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at FSI_0005.ProdS(Tokenizer cnxt)",
      "   at FSI_0007.it@1-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at <StartupCode$FSI_0007>.$FSI_0007.main@()"
     ]
    }
   ],
   "source": [
    "Tokenizer(grammar, true, InputState=\"eaeceaeee\") |> parser |> ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter <<fun:it@1-2>> with token `E`\n",
      "1: S → eaf\n",
      "Enter <<fun:ProdS@58>> with token `A`\n",
      "Match A with A\n",
      "Exit <<fun:ProdS@58>> with token `E`\n",
      "Enter <<fun:ProdS@58-1>> with token `E`\n",
      "Match F with E\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0008.it@1-2.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0008>.$FSI_0008.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0008.it@1-2.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0008>.$FSI_0008.main@()",
      "   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)",
      "   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at FSI_0005.ProdS(Tokenizer cnxt)",
      "   at FSI_0008.it@1-2.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at <StartupCode$FSI_0008>.$FSI_0008.main@()"
     ]
    }
   ],
   "source": [
    "Tokenizer(grammar, true, InputState=\"eaeceaeeceafe\") |> parser |> ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter <<fun:it@1-3>> with token `E`\n",
      "1: S → eaf\n",
      "Enter <<fun:ProdS@58>> with token `A`\n",
      "Match A with A\n",
      "Exit <<fun:ProdS@58>> with token `E`\n",
      "Enter <<fun:ProdS@58-1>> with token `E`\n",
      "Match F with E\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0009.it@1-3.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0009>.$FSI_0009.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0009.it@1-3.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0009>.$FSI_0009.main@()",
      "   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)",
      "   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at FSI_0005.ProdS(Tokenizer cnxt)",
      "   at FSI_0009.it@1-3.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at <StartupCode$FSI_0009>.$FSI_0009.main@()"
     ]
    }
   ],
   "source": [
    "Tokenizer(grammar, true, InputState=\"eaeceafceaeeceafe\") |> parser |> ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter <<fun:it@1-4>> with token `E`\n",
      "1: S → eaf\n",
      "Enter <<fun:ProdS@58>> with token `A`\n",
      "Match A with A\n",
      "Exit <<fun:ProdS@58>> with token `E`\n",
      "Enter <<fun:ProdS@58-1>> with token `E`\n",
      "Match F with E\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0010.it@1-4.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0010>.$FSI_0010.main@()",
     "output_type": "error",
     "traceback": [
      "System.Exception: Cannot match symbol `F` with `E`\n   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)\n   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at FSI_0005.ProdS(Tokenizer cnxt)\n   at FSI_0010.it@1-4.Invoke(Tokenizer cnxt)\n   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)\n   at <StartupCode$FSI_0010>.$FSI_0010.main@()",
      "   at FSI_0005.Match(TOKEN term, Tokenizer cnxt)",
      "   at FSI_0005.ProdS@58-1.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at FSI_0005.ProdS(Tokenizer cnxt)",
      "   at FSI_0010.it@1-4.Invoke(Tokenizer cnxt)",
      "   at FSI_0005.op_EqualsEqualsGreater(Tokenizer cnxt, FSharpFunc`2 prod)",
      "   at <StartupCode$FSI_0010>.$FSI_0010.main@()"
     ]
    }
   ],
   "source": [
    "Tokenizer(grammar, true, InputState=\"eaeceafceaeee\") |> parser |> ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (F#)",
   "language": "F#",
   "name": ".net-fsharp"
  },
  "language_info": {
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "C#",
   "pygments_lexer": "fsharp",
   "version": "4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
